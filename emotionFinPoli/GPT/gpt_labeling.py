import json
import openai
import subprocess
import os
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
load_dotenv()  # .env íŒŒì¼ ìë™ ë¡œë“œ


# âœ… API í‚¤
openai.api_key = os.getenv("OPENAI_API_KEY")

# âœ… ì˜¤ëŠ˜ ë‚ ì§œ
DATE = datetime.datetime.utcnow().strftime("%Y-%m-%d")  # ì´ ì¤„ì„ ì£¼ì„ ì²˜ë¦¬
# DATE = "2025-04-08"  # ê³ ì •ëœ ë‚ ì§œë¡œ ì„¤ì •

# âœ… ì†ŒìŠ¤ ì¢…ë¥˜
SOURCES = ["news", "reddit"]

# âœ… ê³µí†µ GCS ì„¤ì •
GCS_BUCKET = "emotion-index-data"

# âœ… GPT ê°ì • ë¼ë²¨ë§ í•¨ìˆ˜
def label_cluster(cluster_id, sentences):
    prompt = "\n".join([f"{i+1}. {s}" for i, s in enumerate(sentences)])
    messages = [
        {"role": "system", "content": "Read the following sentences and provide ONE single emotion label in English. Respond with only one word. Examples: anxiety, anticipation, anger, cynicism, etc."},
        {"role": "user", "content": prompt}
    ]
    try:
        # API í‚¤ í™•ì¸ ë° í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            print(f"âŒ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return "API í‚¤ ì˜¤ë¥˜"
            
        client = openai.OpenAI(api_key=api_key)
        # "gpt-4"ì—ì„œ "gpt-4o"ë¡œ ë³€ê²½
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            temperature=0.3
        )
        label = response.choices[0].message.content.strip()
        print(f"[cluster {cluster_id}] â†’ {label}")
        return label
    except Exception as e:
        print(f"âŒ Error labeling cluster {cluster_id}: {e}")
        return "Unknown"

# âœ… ë‹¨ì¼ ì†ŒìŠ¤ ì²˜ë¦¬ í•¨ìˆ˜
def process_source(source):
    print(f"\nğŸ“¦ Processing: {source}")
    base_gcs_path = f"gs://{GCS_BUCKET}/{source}/{DATE}/"

    gcs_input = base_gcs_path + "cluster_representative_texts.json"
    gcs_output = base_gcs_path + "cluster_labels.json"

    local_input = Path(f"/tmp/{source}_cluster_representative_texts.json")
    local_output = Path(f"/tmp/{source}_cluster_labels.json")

    try:
        subprocess.run(["gsutil", "cp", gcs_input, str(local_input)], check=True)
        print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {gcs_input}")
    except subprocess.CalledProcessError:
        print(f"âŒ íŒŒì¼ ì—†ìŒ ë˜ëŠ” ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {gcs_input}")
        return

    with open(local_input, "r", encoding="utf-8") as f:
        cluster_texts = json.load(f)

    cluster_labels = {}
    # í´ëŸ¬ìŠ¤í„° IDë³„ë¡œ ê·¸ë£¹í™” (cluster_0, cluster_1 ë“±)
    clusters = {}
    for key, value in cluster_texts.items():
        if "_" in key:
            parts = key.split("_")
            cluster_id = parts[1]  # cluster_0_top1 -> 0
            if cluster_id not in clusters:
                clusters[cluster_id] = []
            
            # sizeëŠ” ìˆ«ìë¼ì„œ ì œì™¸
            if "size" not in key and isinstance(value, str) and value.strip():
                clusters[cluster_id].append(value)
    
    # ê° í´ëŸ¬ìŠ¤í„°ë³„ë¡œ GPT ë¼ë²¨ë§
    for cluster_id, texts in clusters.items():
        if texts:  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ ì²˜ë¦¬
            label = label_cluster(cluster_id, texts[:5])  # ìµœëŒ€ 5ê°œ í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©
            cluster_labels[f"cluster_{cluster_id}"] = label

    with open(local_output, "w", encoding="utf-8") as f:
        json.dump(cluster_labels, f, ensure_ascii=False, indent=2)

    subprocess.run(["gsutil", "cp", str(local_output), gcs_output], check=True)
    print(f"âœ… GCS ì—…ë¡œë“œ ì™„ë£Œ: {gcs_output}")

# âœ… ë©”ì¸ ì‹¤í–‰
def main():
    for source in SOURCES:
        process_source(source)

if __name__ == "__main__":
    main()
