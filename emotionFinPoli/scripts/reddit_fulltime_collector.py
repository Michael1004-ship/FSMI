import os
import json
import datetime
import logging
import pandas as pd
import praw
from google.cloud import storage
from time import sleep
import sys
from dotenv import load_dotenv

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# âœ… ì„¤ì •
SUBREDDITS = [
    # ê²½ì œ ê´€ë ¨
    "economics", "economy", "MacroEconomics", "EconMonitor",
    # ê¸ˆìœµ ê´€ë ¨
    "finance", "investing", "financialindependence", "personalfinance",
    "wallstreetbets", "stocks", "StockMarket", "dividends",
    # ê°ì • ê¸°ë°˜ íë¦„
    "anxiety", "depression", "offmychest"
]

BUCKET_NAME = "emotion-raw-data"
POST_LIMIT = 1000  # ì„œë¸Œë ˆë”§ ì „ì²´ ìˆ˜ì§‘ ê¸°ì¤€

# âœ… ì£¼ì˜ ì•Œë¦¼
print("\033[91mâš ï¸  Reddit APIëŠ” ìµœëŒ€ 1ë…„ ì´ë‚´ ê²Œì‹œë¬¼ë§Œ ìˆ˜ì§‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\033[0m")

# âœ… ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("reddit_full_collector.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("reddit_full_collector")

# âœ… Reddit API ì´ˆê¸°í™” (.env íŒŒì¼ì—ì„œ ë¡œë“œ)
reddit = praw.Reddit(
    client_id=os.getenv("REDDIT_CLIENT_ID"),
    client_secret=os.getenv("REDDIT_CLIENT_SECRET"),
    user_agent=os.getenv("REDDIT_USER_AGENT"),
)

# âœ… ì €ì¥ í•¨ìˆ˜
def save_to_gcs(df, subreddit, date_str):
    # ëª¨ë“  ì„œë¸Œë ˆë”§ì˜ ë°ì´í„°ì— ì„œë¸Œë ˆë”§ ì •ë³´ ì¶”ê°€
    df['subreddit'] = subreddit
    
    # GDELTì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ íŒŒì¼ëª… ì§€ì •
    file_path = f"sns/reddit/full/{date_str}.json"
    
    storage_client = storage.Client()
    bucket = storage_client.bucket(BUCKET_NAME)
    blob = bucket.blob(file_path)
    
    # ê¸°ì¡´ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸í•˜ì—¬ ë³‘í•©
    if blob.exists():
        try:
            existing_data = json.loads(blob.download_as_string())
            combined_data = existing_data + df.to_dict(orient='records')
            blob.upload_from_string(json.dumps(combined_data, ensure_ascii=False), content_type='application/json')
        except Exception as e:
            logger.error(f"ê¸°ì¡´ íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìƒˆ íŒŒì¼ë¡œ ì €ì¥
            blob.upload_from_string(json.dumps(df.to_dict(orient='records'), ensure_ascii=False), content_type='application/json')
    else:
        # ìƒˆ íŒŒì¼ ìƒì„±
        blob.upload_from_string(json.dumps(df.to_dict(orient='records'), ensure_ascii=False), content_type='application/json')
    
    logger.info(f"âœ… ì €ì¥ ì™„ë£Œ: gs://{BUCKET_NAME}/{file_path} (ì„œë¸Œë ˆë”§: {subreddit})")

# âœ… ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def run(start_str, end_str):
    # ë‚ ì§œ ë²”ìœ„ íŒŒì‹±
    start_dt = datetime.datetime.strptime(start_str, "%Y-%m-%d")
    end_dt = datetime.datetime.strptime(end_str, "%Y-%m-%d")
    
    logger.info(f"ğŸš€ Reddit ì „ì²´ ìˆ˜ì§‘ ì‹œì‘: {start_str} ~ {end_str}")
    logger.info(f"ğŸ“‹ ì´ {len(SUBREDDITS)}ê°œ ì„œë¸Œë ˆë”§ ìˆ˜ì§‘ ì˜ˆì •")
    
    # GDELTì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ íŒŒì¼ëª… ìƒì„±
    date_range = f"{start_str}_to_{end_str}"
    
    # ì „ì²´ ì§„í–‰ ìƒí™© ì¶”ì 
    total_subreddits = len(SUBREDDITS)
    total_posts_collected = 0
    start_time = datetime.datetime.now()
    subreddit_results = {}
    
    for idx, sub in enumerate(SUBREDDITS):
        # ì„œë¸Œë ˆë”§ ì§„í–‰ë¥  í‘œì‹œ
        progress = (idx / total_subreddits) * 100
        elapsed = (datetime.datetime.now() - start_time).total_seconds()
        remaining = 0 if idx == 0 else (elapsed / idx) * (total_subreddits - idx)
        
        logger.info(f"ğŸ”„ ì „ì²´ ì§„í–‰ë¥ : {progress:.1f}% ({idx+1}/{total_subreddits}) - "
                   f"ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {remaining/60:.1f}ë¶„")
        logger.info(f"ğŸ“¦ ì„œë¸Œë ˆë”§ ìˆ˜ì§‘ ì‹œì‘: r/{sub} ({start_str} ~ {end_str})")
        
        posts = []
        subreddit_start_time = datetime.datetime.now()

        try:
            # ìˆ˜ì§‘ ì‹œê°„ í•„í„° ì„¤ì •
            # Reddit APIëŠ” íŠ¹ì • ë‚ ì§œ ë²”ìœ„ ì§€ì •ì´ ì œí•œì ì´ë¯€ë¡œ ì‹œê°„ í•„í„°ë¡œ ëŒ€ëµ ì ‘ê·¼
            time_filter = 'all'  # ê¸°ë³¸ê°’
            
            # í˜„ì¬ ì‹œì ìœ¼ë¡œë¶€í„° ë‚ ì§œ ì°¨ì´ ê³„ì‚°
            days_diff = (datetime.utcnow().date() - start_dt.date()).days
            
            if days_diff <= 1:
                time_filter = 'day'
            elif days_diff <= 7:
                time_filter = 'week'
            elif days_diff <= 30:
                time_filter = 'month'
            elif days_diff <= 90:
                time_filter = 'month'
            elif days_diff <= 365:
                time_filter = 'year'
            else:
                time_filter = 'all'
                logger.warning(f"âš ï¸ 1ë…„ ì´ìƒ ì§€ë‚œ ë°ì´í„°ëŠ” ì™„ì „íˆ ìˆ˜ì§‘ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                
            logger.info(f"ğŸ•’ ì‹œê°„ í•„í„°: {time_filter} (í˜„ì¬ ì‹œì ë¶€í„° {days_diff}ì¼ ì „)")
            
            # ìˆ˜ì§‘ ì˜ˆìƒ ê²Œì‹œë¬¼ ìˆ˜ ì•ˆë‚´
            logger.info(f"ğŸ’¬ ìµœëŒ€ {POST_LIMIT}ê°œ ê²Œì‹œë¬¼ íƒìƒ‰ ì˜ˆì •")
            
            # ë°ì´í„° ìˆ˜ì§‘
            collected_count = 0
            matched_count = 0
            
            for submission in reddit.subreddit(sub).top(limit=POST_LIMIT, time_filter=time_filter):
                collected_count += 1
                
                # 100ê°œë§ˆë‹¤ ë¡œê·¸ ì¶”ê°€ ë° ì˜ˆìƒ ì‹œê°„ ê³„ì‚°
                if collected_count % 100 == 0 or collected_count == 1:
                    progress = (collected_count / POST_LIMIT) * 100
                    elapsed_sub = (datetime.datetime.now() - subreddit_start_time).total_seconds()
                    remaining_sub = 0 if collected_count == 0 else (elapsed_sub / collected_count) * (POST_LIMIT - collected_count)
                    
                    logger.info(f"  â†’ í˜„ì¬ {collected_count}/{POST_LIMIT}ê°œ íƒìƒ‰ ì¤‘... ({progress:.1f}%)")
                    logger.info(f"  â†’ í•´ë‹¹ ì„œë¸Œë ˆë”§ ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {remaining_sub/60:.1f}ë¶„")
                    logger.info(f"  â†’ ë‚ ì§œ ë²”ìœ„ì— ë§ëŠ” ê²Œì‹œë¬¼: {matched_count}ê°œ")
                
                # ë‚ ì§œ ë²”ìœ„ í•„í„°ë§
                created_dt = datetime.datetime.utcfromtimestamp(submission.created_utc)
                if start_dt <= created_dt <= end_dt:
                    posts.append({
                        "id": submission.id,
                        "title": submission.title,
                        "selftext": submission.selftext,
                        "created_utc": created_dt.isoformat(),
                        "score": submission.score,
                        "num_comments": submission.num_comments,
                        "url": submission.url
                    })
                    matched_count += 1
                    
                    # 50ê°œë§ˆë‹¤ ë‚ ì§œ ë²”ìœ„ ë¡œê¹…
                    if matched_count % 50 == 0:
                        logger.info(f"  â†’ âœ“ {matched_count}ê°œ ê²Œì‹œë¬¼ ìˆ˜ì§‘ë¨ (ë‚ ì§œ ë²”ìœ„ ë‚´)")
                        
                sleep(0.5)  # ìš”ì²­ ê°„ rate limit ë°©ì§€

            # ì„œë¸Œë ˆë”§ ìˆ˜ì§‘ ì™„ë£Œ ìƒíƒœ ì €ì¥
            subreddit_elapsed = (datetime.datetime.now() - subreddit_start_time).total_seconds()
            subreddit_results[sub] = {
                "collected": matched_count,
                "searched": collected_count,
                "time_taken": subreddit_elapsed,
                "time_filter": time_filter
            }
            
            logger.info(f"âœ… r/{sub} íƒìƒ‰ ì™„ë£Œ ({collected_count}ê°œ ì¤‘ {matched_count}ê°œ ìˆ˜ì§‘, "
                      f"ì†Œìš” ì‹œê°„: {subreddit_elapsed/60:.1f}ë¶„)")

        except Exception as e:
            logger.error(f"ğŸ”´ r/{sub} ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            subreddit_results[sub] = {"error": str(e), "collected": 0}
            continue

        df = pd.DataFrame(posts)
        if df.empty:
            logger.warning(f"âš ï¸ ìˆ˜ì§‘ëœ ê¸€ ì—†ìŒ: r/{sub}")
            continue

        total_posts_collected += len(df)
        logger.info(f"ğŸ“Š r/{sub}ì—ì„œ {len(df)}ê°œ ê²Œì‹œë¬¼ ìˆ˜ì§‘ë¨")
        save_to_gcs(df, sub, date_range)

    # ì „ì²´ ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½
    total_elapsed = (datetime.datetime.now() - start_time).total_seconds()
    logger.info("\n" + "="*50)
    logger.info(f"ğŸ“ˆ Reddit ìˆ˜ì§‘ ìµœì¢… ê²°ê³¼:")
    logger.info(f"  â€¢ ìˆ˜ì§‘ ê¸°ê°„: {start_str} ~ {end_str}")
    logger.info(f"  â€¢ ì´ ì„œë¸Œë ˆë”§ ìˆ˜: {len(SUBREDDITS)}ê°œ")
    logger.info(f"  â€¢ ì´ ìˆ˜ì§‘ ê²Œì‹œë¬¼: {total_posts_collected}ê°œ")
    logger.info(f"  â€¢ ì´ ì†Œìš” ì‹œê°„: {total_elapsed/60:.1f}ë¶„")
    
    logger.info("\nğŸ” ì„œë¸Œë ˆë”§ë³„ ìˆ˜ì§‘ ìƒì„¸:")
    for sub, result in subreddit_results.items():
        if "error" in result:
            logger.info(f"  â€¢ r/{sub}: ì˜¤ë¥˜ ë°œìƒ - {result['error']}")
        else:
            success_rate = (result['collected'] / result['searched'] * 100) if result['searched'] > 0 else 0
            logger.info(f"  â€¢ r/{sub}: {result['collected']}ê°œ ìˆ˜ì§‘ / {result['searched']}ê°œ íƒìƒ‰ "
                      f"({success_rate:.1f}%) - ì†Œìš” ì‹œê°„: {result['time_taken']/60:.1f}ë¶„")
    
    logger.info("="*50)
    logger.info("ğŸ‰ ì „ì²´ Reddit ìˆ˜ì§‘ ì™„ë£Œ!")

if __name__ == "__main__":
    # ëª…ë ¹ì¤„ ì¸ì í™•ì¸
    if len(sys.argv) >= 3:
        start = sys.argv[1]
        end = sys.argv[2]
    else:
        # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
        print("Reddit ë°ì´í„° ìˆ˜ì§‘ ë„êµ¬")
        print("-" * 30)
        start = input("ì‹œì‘ì¼ (YYYY-MM-DD í˜•ì‹): ")
        end = input("ì¢…ë£Œì¼ (YYYY-MM-DD í˜•ì‹): ")
    
    # ë‚ ì§œ í˜•ì‹ ê²€ì¦ (YYYY-MM-DD)
    try:
        datetime.datetime.strptime(start, "%Y-%m-%d")
        datetime.datetime.strptime(end, "%Y-%m-%d")
    except ValueError:
        print("ì˜¤ë¥˜: ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        sys.exit(1)
    
    logger.info(f"ìˆ˜ì§‘ ê¸°ê°„: {start} ~ {end}")
    run(start, end)