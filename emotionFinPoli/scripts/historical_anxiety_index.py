from datetime import datetime, timedelta
# historical_anxiety_index.py
import os
import sys
import logging
import argparse
import subprocess

from pathlib import Path
from google.cloud import storage

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ì„¤ì •
LOG_ROOT = "/home/hwangjeongmun691/logs"
today = datetime.utcnow().strftime("%Y-%m-%d")
LOG_DATE_DIR = f"{LOG_ROOT}/{today}"

# ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(LOG_DATE_DIR, exist_ok=True)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f"{LOG_DATE_DIR}/historical_anxiety_index.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("historical_anxiety")

# ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ (ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©)
PROJECT_ROOT = "/home/hwangjeongmun691/projects/emotionFinPoli"
GDELT_FINBERT = os.path.join(PROJECT_ROOT, "scripts/gdelt_realtime_crawling&FinBERT.py")
REDDIT_FINBERT = os.path.join(PROJECT_ROOT, "scripts/reddit_FinBERT.py")
REDDIT_ROBERTA = os.path.join(PROJECT_ROOT, "scripts/reddit_RoBERTa.py")
BUILD_INDEX = os.path.join(PROJECT_ROOT, "building_index/build_anxiety_index.py")

def run_script(script_path, description, env_vars=None):
    """ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë¡œê¹…í•©ë‹ˆë‹¤."""
    try:
        logger.info(f"âœ¨ {description} ì‹œì‘...")
        
        # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
        env = os.environ.copy()
        if env_vars:
            env.update(env_vars)
            
        result = subprocess.run(
            [sys.executable, script_path], 
            env=env,
            capture_output=True, 
            text=True, 
            check=True
        )
        
        if result.stdout:
            for line in result.stdout.splitlines():
                logger.info(f"[{description}] {line}")
        
        if result.stderr:
            for line in result.stderr.splitlines():
                logger.warning(f"[{description}] {line}")
        
        logger.info(f"âœ… {description} ì™„ë£Œ")
        return True
    except subprocess.CalledProcessError as e:
        logger.error(f"âŒ {description} ì‹¤íŒ¨: ì¢…ë£Œ ì½”ë“œ {e.returncode}")
        if e.stdout:
            logger.error(f"ì¶œë ¥: {e.stdout}")
        if e.stderr:
            logger.error(f"ì—ëŸ¬: {e.stderr}")
        return False
    except Exception as e:
        logger.error(f"âŒ {description} ì‹¤íŒ¨: {e}")
        return False

def create_modified_script(original_path, output_path, target_date):
    """ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì„ ë³µì‚¬í•˜ê³  TARGET_DATE ë³€ìˆ˜ë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤."""
    with open(original_path, 'r') as f:
        content = f.read()
    
    # TARGET_DATE ë³€ìˆ˜ ë³€ê²½
    if "TARGET_DATE" in content:
        modified_content = content.replace(
            'TARGET_DATE = datetime.today().strftime("%Y-%m-%d")',
            f'TARGET_DATE = "{target_date}"'
        ).replace(
            'TARGET_DATE = datetime.utcnow().strftime("%Y-%m-%d")',
            f'TARGET_DATE = "{target_date}"'
        ).replace(
            'TARGET_DATE = "2024-04-07"',  # í•˜ë“œì½”ë”©ëœ ë‚ ì§œ ë³€ê²½
            f'TARGET_DATE = "{target_date}"'
        ).replace(
            'TARGET_DATE = "2025-04-07"',  # í•˜ë“œì½”ë”©ëœ ë‚ ì§œ ë³€ê²½
            f'TARGET_DATE = "{target_date}"'
        )
    else:
        # TARGET_DATE ë³€ìˆ˜ê°€ ì—†ëŠ” ê²½ìš°, ìŠ¤í¬ë¦½íŠ¸ ìƒë‹¨ì— ì¶”ê°€
        modified_content = f'TARGET_DATE = "{target_date}"\n' + content
    
    # ìˆ˜ì •ëœ ìŠ¤í¬ë¦½íŠ¸ ì €ì¥
    with open(output_path, 'w') as f:
        f.write(modified_content)
    
    logger.info(f"ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì • ì™„ë£Œ: {output_path} (TARGET_DATE={target_date})")

def create_modified_gdelt_script(original_path, output_path, target_date):
    """GDELT ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìˆ˜ì •í•˜ì—¬ íŠ¹ì • ë‚ ì§œì˜ ë°ì´í„°ë§Œ ì²˜ë¦¬í•˜ë„ë¡ í•©ë‹ˆë‹¤."""
    with open(original_path, 'r') as f:
        content = f.read()
    
    # ì›ë³¸ ì½”ë“œì—ì„œ json íŒŒì¼ ì°¾ëŠ” ë¶€ë¶„ì„ ìˆ˜ì •
    modified_content = content.replace(
        'prefix_path = f"{GDELT_PREFIX}{TARGET_DATE}/"',
        f'prefix_path = "news/gdelt/full/"'
    )
    
    # ë°ì´í„° ì²˜ë¦¬ ì½”ë“œë¥¼ ì¶”ê°€í•˜ì—¬ íŠ¹ì • ë‚ ì§œ í•„í„°ë§
    filter_code = f'''
# íŠ¹ì • ë‚ ì§œ ë°ì´í„° í•„í„°ë§
TARGET_DATE = "{target_date}"
filtered_items = []
for item in items:
    if "DATE" in item:
        item_date = item["DATE"][:8]  # YYYYMMDDHHMMSS í˜•ì‹ì—ì„œ YYYYMMDD ì¶”ì¶œ
        formatted_date = f"{{item_date[:4]}}-{{item_date[4:6]}}-{{item_date[6:8]}}"
        if formatted_date == TARGET_DATE:
            filtered_items.append(item)
items = filtered_items
    '''
    
    # ìœ„ ì½”ë“œë¥¼ items ë¡œë“œ í›„ ìœ„ì¹˜ì— ì‚½ì…
    modified_content = modified_content.replace(
        'for item in items:',
        f'{filter_code}\nfor item in items:'
    )
    
    # ìˆ˜ì •ëœ ìŠ¤í¬ë¦½íŠ¸ ì €ì¥
    with open(output_path, 'w') as f:
        f.write(modified_content)
    
    logger.info(f"GDELT ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì • ì™„ë£Œ: {output_path} (TARGET_DATE={target_date})")

def check_gcs_file_exists(bucket_name, blob_path):
    """GCSì— íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    try:
        client = storage.Client()
        bucket = client.bucket(bucket_name)
        blob = bucket.blob(blob_path)
        return blob.exists()
    except Exception as e:
        logger.error(f"GCS íŒŒì¼ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        return False

def verify_output_files(date_str):
    """íŠ¹ì • ë‚ ì§œì˜ ì¶œë ¥ íŒŒì¼ì´ ëª¨ë‘ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    bucket_name = "emotion-index-data"
    
    files_to_check = [
        # GDELT FinBERT ê²°ê³¼
        f"news/{date_str}/news_anxiety_index.csv",
        
        # Reddit ë¶„ì„ ê²°ê³¼
        f"reddit/{date_str}/reddit_anxiety_index.csv",
        f"reddit/{date_str}/reddit_anxiety_roberta.csv",
        
        # ìµœì¢… ë¶ˆì•ˆ ì§€ìˆ˜
        f"final_anxiety_index/{date_str}/anxiety_index_final.csv"
    ]
    
    results = {}
    for file_path in files_to_check:
        exists = check_gcs_file_exists(bucket_name, file_path)
        results[file_path] = exists
        status = "âœ… ì¡´ì¬í•¨" if exists else "âŒ ì¡´ì¬í•˜ì§€ ì•ŠìŒ"
        logger.info(f"GCS íŒŒì¼ í™•ì¸: gs://{bucket_name}/{file_path} - {status}")
    
    return all(results.values())

def process_date(target_date):
    """íŠ¹ì • ë‚ ì§œì˜ ë°ì´í„° ì²˜ë¦¬ ë° ë¶ˆì•ˆ ì§€ìˆ˜ ê³„ì‚°."""
    logger.info(f"ğŸ”„ {target_date} ë‚ ì§œ ë°ì´í„° ì²˜ë¦¬ ì‹œì‘")
    process_start_time = datetime.now()
    
    # ì„ì‹œ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ
    temp_dir = Path("/tmp/emotion_scripts")
    temp_dir.mkdir(exist_ok=True)
    
    gdelt_temp = temp_dir / "gdelt_finbert_temp.py"
    reddit_finbert_temp = temp_dir / "reddit_finbert_temp.py"
    reddit_roberta_temp = temp_dir / "reddit_roberta_temp.py"
    
    # ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì • ì‹œì‘
    logger.info(f"ğŸ“ {target_date}ìš© ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„ ì¤‘...")
    script_mod_start = datetime.now()
    
    # GDELT ìŠ¤í¬ë¦½íŠ¸ëŠ” ì „ì²´ ê¸°ê°„ ë°ì´í„°ì—ì„œ íŠ¹ì • ë‚ ì§œ í•„í„°ë§ ë¡œì§ ì¶”ê°€
    create_modified_gdelt_script(GDELT_FINBERT, gdelt_temp, target_date)
    
    # ë‚˜ë¨¸ì§€ Reddit ìŠ¤í¬ë¦½íŠ¸ëŠ” ê¸°ì¡´ ë°©ì‹ëŒ€ë¡œ ìˆ˜ì •
    create_modified_script(REDDIT_FINBERT, reddit_finbert_temp, target_date)
    create_modified_script(REDDIT_ROBERTA, reddit_roberta_temp, target_date)
    
    script_mod_time = (datetime.now() - script_mod_start).total_seconds()
    logger.info(f"âœ… ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {script_mod_time:.2f}ì´ˆ)")
    
    # ë‹¨ê³„ë³„ ì„±ê³µ ì—¬ë¶€ ì¶”ì 
    steps_results = {
        "gdelt": False,
        "reddit_finbert": False,
        "reddit_roberta": False,
        "build_index": False
    }
    
    # 1. GDELT ë°ì´í„° ë¶„ì„ - 1/4 ë‹¨ê³„
    logger.info(f"[1/4] ğŸ” {target_date} GDELT ë°ì´í„° ë¶„ì„ ì‹œì‘...")
    step_start_time = datetime.now()
    
    gdelt_success = run_script(
        str(gdelt_temp),
        f"GDELT {target_date} ë¶„ì„"
    )
    
    step_time = (datetime.now() - step_start_time).total_seconds()
    steps_results["gdelt"] = gdelt_success
    
    if not gdelt_success:
        logger.error(f"âŒ GDELT {target_date} ë¶„ì„ ì‹¤íŒ¨ (ì†Œìš” ì‹œê°„: {step_time/60:.2f}ë¶„), ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
    else:
        # GCS ì €ì¥ í™•ì¸
        gdelt_saved = check_gcs_file_exists("emotion-index-data", f"news/{target_date}/news_anxiety_index.csv")
        if gdelt_saved:
            logger.info(f"âœ… GDELT ë¶„ì„ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {step_time/60:.2f}ë¶„)")
            logger.info(f"  â†’ ì €ì¥ ê²½ë¡œ: gs://emotion-index-data/news/{target_date}/news_anxiety_index.csv")
        else:
            logger.warning(f"âš ï¸ GDELT ë¶„ì„ì€ ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì†Œìš” ì‹œê°„: {step_time/60:.2f}ë¶„)")
    
    # 2. Reddit FinBERT ë¶„ì„ - 2/4 ë‹¨ê³„
    logger.info(f"[2/4] ğŸ” {target_date} Reddit FinBERT ë¶„ì„ ì‹œì‘...")
    step_start_time = datetime.now()
    
    reddit_finbert_success = run_script(
        str(reddit_finbert_temp), 
        f"Reddit FinBERT {target_date} ë¶„ì„"
    )
    
    step_time = (datetime.now() - step_start_time).total_seconds()
    steps_results["reddit_finbert"] = reddit_finbert_success
    
    if not reddit_finbert_success:
        logger.error(f"âŒ Reddit FinBERT {target_date} ë¶„ì„ ì‹¤íŒ¨ (ì†Œìš” ì‹œê°„: {step_time/60:.2f}ë¶„), ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
    else:
        # GCS ì €ì¥ í™•ì¸
        finbert_saved = check_gcs_file_exists("emotion-index-data", f"reddit/{target_date}/reddit_anxiety_index.csv")
        if finbert_saved:
            logger.info(f"âœ… Reddit FinBERT ë¶„ì„ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {step_time/60:.2f}ë¶„)")
            logger.info(f"  â†’ ì €ì¥ ê²½ë¡œ: gs://emotion-index-data/reddit/{target_date}/reddit_anxiety_index.csv")
        else:
            logger.warning(f"âš ï¸ Reddit FinBERT ë¶„ì„ì€ ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì†Œìš” ì‹œê°„: {step_time/60:.2f}ë¶„)")
    
    # 3. Reddit RoBERTa ë¶„ì„ - 3/4 ë‹¨ê³„
    logger.info(f"[3/4] ğŸ” {target_date} Reddit RoBERTa ë¶„ì„ ì‹œì‘...")
    step_start_time = datetime.now()
    
    reddit_roberta_success = run_script(
        str(reddit_roberta_temp),
        f"Reddit RoBERTa {target_date} ë¶„ì„"
    )
    
    step_time = (datetime.now() - step_start_time).total_seconds()
    steps_results["reddit_roberta"] = reddit_roberta_success
    
    if not reddit_roberta_success:
        logger.error(f"âŒ Reddit RoBERTa {target_date} ë¶„ì„ ì‹¤íŒ¨ (ì†Œìš” ì‹œê°„: {step_time/60:.2f}ë¶„), ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
    else:
        # GCS ì €ì¥ í™•ì¸
        roberta_saved = check_gcs_file_exists("emotion-index-data", f"reddit/{target_date}/reddit_anxiety_roberta.csv")
        if roberta_saved:
            logger.info(f"âœ… Reddit RoBERTa ë¶„ì„ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {step_time/60:.2f}ë¶„)")
            logger.info(f"  â†’ ì €ì¥ ê²½ë¡œ: gs://emotion-index-data/reddit/{target_date}/reddit_anxiety_roberta.csv")
        else:
            logger.warning(f"âš ï¸ Reddit RoBERTa ë¶„ì„ì€ ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì†Œìš” ì‹œê°„: {step_time/60:.2f}ë¶„)")
    
    # 4. ë¶ˆì•ˆ ì§€ìˆ˜ ê³„ì‚° - 4/4 ë‹¨ê³„
    logger.info(f"[4/4] ğŸ“Š {target_date} ìµœì¢… ë¶ˆì•ˆ ì§€ìˆ˜ ê³„ì‚° ì‹œì‘...")
    step_start_time = datetime.now()
    
    build_success = run_script(
        BUILD_INDEX,
        f"ë¶ˆì•ˆ ì§€ìˆ˜ ê³„ì‚° {target_date}",
        {"PYTHONPATH": PROJECT_ROOT}
    )
    
    step_time = (datetime.now() - step_start_time).total_seconds()
    steps_results["build_index"] = build_success
    
    if not build_success:
        logger.error(f"âŒ ë¶ˆì•ˆ ì§€ìˆ˜ ê³„ì‚° {target_date} ì‹¤íŒ¨ (ì†Œìš” ì‹œê°„: {step_time/60:.2f}ë¶„)")
    else:
        # GCS ì €ì¥ í™•ì¸
        final_saved = check_gcs_file_exists("emotion-index-data", f"final_anxiety_index/{target_date}/anxiety_index_final.csv")
        if final_saved:
            logger.info(f"âœ… ìµœì¢… ë¶ˆì•ˆ ì§€ìˆ˜ ê³„ì‚° ì™„ë£Œ (ì†Œìš” ì‹œê°„: {step_time/60:.2f}ë¶„)")
            logger.info(f"  â†’ ì €ì¥ ê²½ë¡œ: gs://emotion-index-data/final_anxiety_index/{target_date}/anxiety_index_final.csv")
        else:
            logger.warning(f"âš ï¸ ë¶ˆì•ˆ ì§€ìˆ˜ ê³„ì‚°ì€ ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì†Œìš” ì‹œê°„: {step_time/60:.2f}ë¶„)")
    
    # ëª¨ë“  ì¶œë ¥ íŒŒì¼ ê²€ì¦
    logger.info(f"===== {target_date} ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ =====")
    logger.info("ğŸ“Š ì²˜ë¦¬ ë‹¨ê³„ë³„ ìƒíƒœ:")
    logger.info(f"  â€¢ GDELT ë¶„ì„: {'âœ… ì„±ê³µ' if steps_results['gdelt'] else 'âŒ ì‹¤íŒ¨'}")
    logger.info(f"  â€¢ Reddit FinBERT: {'âœ… ì„±ê³µ' if steps_results['reddit_finbert'] else 'âŒ ì‹¤íŒ¨'}")
    logger.info(f"  â€¢ Reddit RoBERTa: {'âœ… ì„±ê³µ' if steps_results['reddit_roberta'] else 'âŒ ì‹¤íŒ¨'}")
    logger.info(f"  â€¢ ìµœì¢… ë¶ˆì•ˆ ì§€ìˆ˜: {'âœ… ì„±ê³µ' if steps_results['build_index'] else 'âŒ ì‹¤íŒ¨'}")
    
    logger.info(f"ğŸ“ ì¶œë ¥ íŒŒì¼ í™•ì¸ ì¤‘...")
    all_files_exist = verify_output_files(target_date)
    
    # ì „ì²´ ì†Œìš” ì‹œê°„ ê³„ì‚°
    total_time = (datetime.now() - process_start_time).total_seconds()
    
    if all_files_exist:
        logger.info(f"ğŸ‰ {target_date} ëª¨ë“  ì¶œë ¥ íŒŒì¼ì´ GCSì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        logger.info(f"â±ï¸ ì´ ì†Œìš” ì‹œê°„: {total_time/60:.2f}ë¶„")
    else:
        logger.warning(f"âš ï¸ {target_date} ì¼ë¶€ ì¶œë ¥ íŒŒì¼ì´ GCSì— ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        logger.warning(f"â±ï¸ ì´ ì†Œìš” ì‹œê°„: {total_time/60:.2f}ë¶„")
    
    success_rate = sum(1 for v in steps_results.values() if v) / len(steps_results) * 100
    logger.info(f"ğŸ”¢ ì„±ê³µë¥ : {success_rate:.1f}% ({sum(1 for v in steps_results.values() if v)}/{len(steps_results)})")
    
    return build_success

def process_date_range(start_date, end_date):
    """ë‚ ì§œ ë²”ìœ„ì— ëŒ€í•œ ë°ì´í„° ì²˜ë¦¬."""
    start_dt = datetime.strptime(start_date, "%Y-%m-%d")
    end_dt = datetime.strptime(end_date, "%Y-%m-%d")
    
    # ì´ ì¼ìˆ˜ ê³„ì‚°
    total_days = (end_dt - start_dt).days + 1
    logger.info(f"ğŸ—“ï¸ ì´ {total_days}ì¼ ë°ì´í„° ì²˜ë¦¬ ì‹œì‘: {start_date} ~ {end_date}")
    
    # ì „ì²´ ì‹¤í–‰ ì‹œì‘ ì‹œê°„
    range_start_time = datetime.now()
    
    # ê²°ê³¼ ì €ì¥
    results = []
    successful_days = 0
    
    # ì‹œì‘ì¼ë¶€í„° ì¢…ë£Œì¼ê¹Œì§€ ë°˜ë³µ
    current_dt = start_dt
    for day_index in range(total_days):
        date_str = current_dt.strftime("%Y-%m-%d")
        
        # ì§„í–‰ ìƒí™© í‘œì‹œ
        progress = (day_index / total_days) * 100
        elapsed = (datetime.now() - range_start_time).total_seconds()
        remaining = 0 if day_index == 0 else (elapsed / day_index) * (total_days - day_index)
        
        logger.info(f"\n{'='*50}")
        logger.info(f"ğŸ”„ ì „ì²´ ì§„í–‰ë¥ : {progress:.1f}% - {day_index+1}/{total_days}ì¼ ì²˜ë¦¬ ì¤‘")
        logger.info(f"â±ï¸ ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {remaining/60:.1f}ë¶„ ({remaining/3600:.2f}ì‹œê°„)")
        logger.info(f"ğŸ“… í˜„ì¬ ì²˜ë¦¬ ë‚ ì§œ: {date_str} ({day_index+1}ì¼ì°¨)")
        logger.info(f"{'='*50}\n")
        
        # í•´ë‹¹ ë‚ ì§œ ì²˜ë¦¬
        day_start_time = datetime.now()
        success = process_date(date_str)
        day_elapsed = (datetime.now() - day_start_time).total_seconds()
        
        # ê²°ê³¼ ì €ì¥
        status = "âœ… ì„±ê³µ" if success else "âŒ ì‹¤íŒ¨"
        results.append((date_str, success, day_elapsed))
        
        if success:
            successful_days += 1
            
        logger.info(f"ğŸ“‹ {date_str} ì²˜ë¦¬ ê²°ê³¼: {status} (ì†Œìš” ì‹œê°„: {day_elapsed/60:.2f}ë¶„)")
        logger.info(f"í˜„ì¬ê¹Œì§€ {successful_days}/{day_index+1} ì¼ ì„±ê³µ (ì„±ê³µë¥ : {(successful_days/(day_index+1))*100:.1f}%)")
        
        # ë‹¤ìŒ ë‚ ì§œë¡œ ì´ë™
        current_dt += timedelta(days=1)
    
    # ì „ì²´ ì‹¤í–‰ ê²°ê³¼ ìš”ì•½
    total_elapsed = (datetime.now() - range_start_time).total_seconds()
    success_rate = (successful_days / total_days) * 100
    
    logger.info("\n" + "="*60)
    logger.info(f"ğŸ“Š {start_date} ~ {end_date} ì²˜ë¦¬ ìµœì¢… ê²°ê³¼")
    logger.info(f"  â€¢ ì´ ì²˜ë¦¬ ì¼ìˆ˜: {total_days}ì¼")
    logger.info(f"  â€¢ ì„±ê³µí•œ ì¼ìˆ˜: {successful_days}ì¼")
    logger.info(f"  â€¢ ì‹¤íŒ¨í•œ ì¼ìˆ˜: {total_days - successful_days}ì¼")
    logger.info(f"  â€¢ ì„±ê³µë¥ : {success_rate:.1f}%")
    logger.info(f"  â€¢ ì´ ì†Œìš” ì‹œê°„: {total_elapsed/60:.2f}ë¶„ ({total_elapsed/3600:.2f}ì‹œê°„)")
    logger.info(f"  â€¢ ì¼ í‰ê·  ì†Œìš” ì‹œê°„: {(total_elapsed/total_days)/60:.2f}ë¶„")
    
    # ì¼ë³„ ì²˜ë¦¬ ê²°ê³¼ ìƒì„¸ í‘œì‹œ
    logger.info("\nğŸ” ì¼ë³„ ì²˜ë¦¬ ê²°ê³¼:")
    for date_str, success, elapsed in results:
        status = "âœ… ì„±ê³µ" if success else "âŒ ì‹¤íŒ¨"
        logger.info(f"  â€¢ {date_str}: {status} (ì†Œìš” ì‹œê°„: {elapsed/60:.2f}ë¶„)")
    
    logger.info("="*60)
    logger.info(f"ğŸ‰ {start_date} ~ {end_date} ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ!")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ê³¼ê±° ë°ì´í„°ë¡œ ë¶ˆì•ˆ ì§€ìˆ˜ ê³„ì‚°")
    parser.add_argument("--start", help="ì‹œì‘ì¼ (YYYY-MM-DD)")
    parser.add_argument("--end", help="ì¢…ë£Œì¼ (YYYY-MM-DD)")
    args = parser.parse_args()
    
    # ëª…ë ¹ì¤„ ì¸ìê°€ ì—†ìœ¼ë©´ ì‚¬ìš©ì ì…ë ¥ ìš”ì²­
    if not args.start or not args.end:
        print("\n===== ê³¼ê±° ë°ì´í„° ë¶ˆì•ˆ ì§€ìˆ˜ ê³„ì‚° =====")
        print("ì²˜ë¦¬í•  ë‚ ì§œ ë²”ìœ„ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (YYYY-MM-DD í˜•ì‹)")
        if not args.start:
            args.start = input("ì‹œì‘ì¼: ")
        if not args.end:
            args.end = input("ì¢…ë£Œì¼: ")
    
    # ë‚ ì§œ í˜•ì‹ ê²€ì¦
    try:
        start_dt = datetime.strptime(args.start, "%Y-%m-%d")
        end_dt = datetime.strptime(args.end, "%Y-%m-%d")
        
        # ë‚ ì§œ ë²”ìœ„ ìœ íš¨ì„± ê²€ì‚¬
        if start_dt > end_dt:
            print("ì˜¤ë¥˜: ì‹œì‘ì¼ì´ ì¢…ë£Œì¼ë³´ë‹¤ ëŠ¦ìŠµë‹ˆë‹¤.")
            sys.exit(1)
            
        # ë„ˆë¬´ ê¸´ ë²”ìœ„ ê²½ê³ 
        days_diff = (end_dt - start_dt).days
        if days_diff > 30:
            confirm = input(f"âš ï¸ {days_diff}ì¼ì˜ ê¸´ ê¸°ê°„ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
            if confirm.lower() != 'y':
                print("ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                sys.exit(0)
                
    except ValueError:
        print("ì˜¤ë¥˜: ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        sys.exit(1)
    
    print(f"\nì²˜ë¦¬ ì‹œì‘: {args.start} ~ {args.end}")
    print(f"ì´ {(end_dt - start_dt).days + 1}ì¼ ë°ì´í„° ì²˜ë¦¬ ì˜ˆì •")
    print("=" * 40)
    
    logger.info(f"ê³¼ê±° ë°ì´í„° ì²˜ë¦¬ ì‹œì‘: {args.start} ~ {args.end}")
    process_date_range(args.start, args.end)